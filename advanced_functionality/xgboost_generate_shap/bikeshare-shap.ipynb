{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\n",
    "\n",
    "In this notebook, we'll be building a simple regression model to predict hourly bike rentals using a popular dataset. There are two goals for this notebook:\n",
    "\n",
    "1. Show how XGBoost can be used to build a regression model\n",
    "2. Describe various SHAP visualizations we can build to understand our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This dataset contains daily counts of rented bicycles from the bicycle rental company Capital-Bikeshare in Washington D.C., along with weather and seasonal information. The goal is to predict how many bikes will be rented depending on the weather and the day. The data can be downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset).\n",
    "\n",
    "Features available in the dataset: \n",
    "\n",
    "- Count of bicycles including both casual and registered users. The count is used as the target in the regression task.\n",
    "- The season, either spring, summer, fall or winter.\n",
    "- Indicator whether the day was a holiday or not.\n",
    "- The year, either 2011 or 2012.\n",
    "- The hour of day : 0 to 23\n",
    "- Number of days since the 01.01.2011 (the first day in the dataset).\n",
    "- Indicator whether the day was a working day or weekend.\n",
    "- The weather situation on that day. One of:\n",
    "    - clear, few clouds, partly cloudy, cloudy\n",
    "    - mist + clouds, mist + broken clouds, mist + few clouds, mist\n",
    "    - light snow, light rain + thunderstorm + scattered clouds, light rain + scattered clouds\n",
    "    - heavy rain + ice pallets + thunderstorm + mist, snow + mist\n",
    "- Temperature in degrees Celsius.\n",
    "- Relative humidity in percent (0 to 100).\n",
    "- Wind speed in km per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation and imports\n",
    "\n",
    "This notebook was created and tested on an ml.m5.2xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = '<add bucket name>'\n",
    "prefix = 'sagemaker/DEMO-xgboost-bikeshare'\n",
    " \n",
    "# Define IAM role: automatically get the role if run on a SageMaker instance\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import pickle as pkl                              # For serializing/deserializing model\n",
    "import sagemaker                                  # Amazon SageMaker's Python SDK provides many helper functions\n",
    "import os                                         # For manipulating filepath names\n",
    "from sklearn.model_selection import train_test_split   # For splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Let's start by downloading the dataset from UCI's ML Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
    "!unzip -o Bike-Sharing-Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hour.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "1. Replace column names with meaningful names\n",
    "2. One-hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'weathersit':'weather',\n",
    "                     'mnth':'month',\n",
    "                     'hr':'hour',\n",
    "                     'hum': 'humidity',\n",
    "                     'cnt':'count'},\n",
    "            inplace=True)\n",
    "data = data.drop(['registered', 'casual', 'instant','dteday','yr'], axis=1)\n",
    "\n",
    "categorical_columns = ['season', 'month', 'hour', 'holiday', 'weekday', 'weather']\n",
    "categorical_col_values = {'season': ['spring', 'summer', 'fall', 'winter'], \n",
    "                          'month': ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "                          'hour': range(24), \n",
    "                          'holiday': ['no', 'yes'], \n",
    "                          'weekday': ['sun', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat'], \n",
    "                          'weather': ['clear', 'mist', 'snow', 'rain']}\n",
    "\n",
    "data_dummy = pd.get_dummies(data, prefix=categorical_columns, columns=categorical_columns, drop_first=True)\n",
    "data_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_dummy.loc[:, \"count\"]\n",
    "X = data_dummy.drop(\"count\", axis=1)\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "pd.concat([y_train, X_train], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "pd.concat([y_test, X_test], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Source distributed script mode\n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# use validation set to choose # of trees\n",
    "hyperparams = {\n",
    "    \"eta\": 0.02,\n",
    "    \"max_depth\": 3, \n",
    "    \"subsample\": 0.5, \n",
    "    \"verbose\": 0, \n",
    "    'num_round': 5000\n",
    "}\n",
    "\n",
    "instance_type = \"ml.c5.2xlarge\"\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "content_type = \"csv\"\n",
    "train_input = s3_input(\"s3://{}/{}/{}\".format(bucket, prefix, 'data/train.csv'), content_type=content_type)\n",
    "validation_input = s3_input(\"s3://{}/{}/{}\".format(bucket, prefix, 'data/test.csv'), content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "session = Session(boto_session=boto_session)\n",
    "script_path = 'bikeshare-script.py'\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    entry_point=script_path,\n",
    "    framework_version='0.90-1', # Note: framework_version is mandatory\n",
    "    hyperparameters=hyperparams,\n",
    "    role=role,\n",
    "    train_instance_count=1, \n",
    "    train_instance_type=instance_type,\n",
    "    #train_instance_type='local',\n",
    "    output_path=output_path)\n",
    "\n",
    "xgb_script_mode_estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "filepath = urlparse(xgb_script_mode_estimator.model_data, allow_fragments=False).path.lstrip('/')\n",
    "client = boto3.client('s3')\n",
    "client.download_file(bucket, filepath, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the model using SHAP\n",
    "\n",
    "We use SHAP values as means to understand the contributions of the features to the model predictions. SHAP (SHapley Additive exPlanations) by Lundberg and Lee (2016) is a method to\n",
    "explain individual predictions and is based on the game theoretically optimal\n",
    "Shapley Values.\n",
    "\n",
    "A prediction can be explained by assuming that each feature value of the\n",
    "instance is a “player” in a game where the prediction is the payout. Shapley\n",
    "values – a method from coalitional game theory – tells us how to fairly\n",
    "distribute the “payout” among the features.\n",
    "\n",
    "**Be careful to interpret the Shapley value correctly**: The Shapley value is the\n",
    "average contribution of a feature value to the prediction in different\n",
    "coalitions. The Shapley value is NOT the difference in prediction when we would\n",
    "remove the feature from the model.\n",
    "\n",
    "Reference: \"Explainable machine-learning predictions for the prevention of hypoxaemia during surgery\", Nature Biomedical Engineering, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "model = pkl.load(open('xgboost-model', 'rb'))\n",
    "# shap_values = pkl.load(open('shap-values', 'rb'))\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A global aggregation of the individual Shapley values gives the overall average contributions of the features. The plot below shows that `temp` plays an important role in number of bikes rented. Similarly, the time of day (specifically, morning and evening rush hours) also play a pivotal role is predicting the number of bikes rented an hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **summary plot** below can provide more context over the bar chart of feature importances. It tells which features are most important, and also their range of effects over the dataset. The color allows us match how changes in the value of a feature effect the change in risk (such that a high `temp` leads to more bike rentals while higher `humidity` leads to reduction in count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **SHAP dependence plot** shows how the model output varies by feature value while showing the interaction between two features. The feature used for coloring is automatically chosen to highlight what might be driving these interactions. \n",
    "\n",
    "The plot below indicates that interaction between `temp` and `humidity`. As temperatures increase, the SHAP values increase which implies that bikes are rented more on hotter days/hours. For any particular temperature, increase in humidity leads to lower bike rentals as indicated by the color in any column of `temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"temp\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below **dependence plot** shows that, in general, presence of `hour_8` (i.e. at 8 am) bike rental counts are higher than the average. Further, this effect is, expectedly, higher on a working day (red color in the plot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"hour_8\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **force plot** explanation shows how features are contributing to push the model output from the base value (the average model output over the dataset) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue \n",
    "\n",
    "Plot below indicates that for this particular data point the prediction (232.27) is higher than the average (190.1) primarily because this is 9 am on a hot (`temp=0.7`, approx 25 C) summer day. The fact that it's not a working day reduces the count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[100, :], X_test.iloc[100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, for the data point below, the prediction (51.52) is much lower than average because it's 5 am with `temp=0.36` (approx 10 C). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[1000, :], X_test.iloc[1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix (delete before publishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn                              # Seaborn visualization library\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sn.pointplot(data=data[['hour',\n",
    "                       'count',\n",
    "                       'weekday']],\n",
    "            x='hour', y='count',\n",
    "            hue='weekday', ax=ax)\n",
    "ax.set(title=\"Use of the system during weekdays and weekends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sn.barplot(data=data[['month',\n",
    "                      'count']],\n",
    "            x='month', y='count')\n",
    "ax.set(title=\"Monthly distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_full = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "xgb_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# use validation set to choose # of trees\n",
    "params = {\n",
    "    \"eta\": 0.02,\n",
    "    \"max_depth\": 3, \n",
    "    \"subsample\": 0.5, \n",
    "    \"verbose\": 1\n",
    "}\n",
    "model_train = xgboost.train(params, xgb_train, 10000, evals = [(xgb_test, \"test\")], verbose_eval=1000)\n",
    "model = xgboost.train(params, xgb_full, 5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
