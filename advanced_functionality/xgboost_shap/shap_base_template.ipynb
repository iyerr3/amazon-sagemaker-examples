{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability for XGBoost models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import pickle as pkl    \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following parameters are used in the notebook visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model (XGBoost booster) file ## \n",
    "\n",
    "# s3.download_file('BUCKET_NAME', 'MODEL_LOCATION', 'xgboost_model')\n",
    "model = pkl.load(open('xgboost_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shap values ##\n",
    "\n",
    "# s3.download_file('BUCKET_NAME', 'SHAP_LOCATION', 'shap_values')\n",
    "shap_values = pkl.load(open('shap_values', 'rb'))\n",
    "N_ROWS = shap_values.shape[0]\n",
    "N_FEATURES = shap_values.shape[1]\n",
    "\n",
    "baseline_value = shap_values[0, -1]  # last column is the baseline\n",
    "shap_values = np.delete(shap_values, -1, axis=1) # remove the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature_names ## \n",
    "\n",
    "feature_names = None\n",
    "# if feature names are not available then create a dummy list\n",
    "if not feature_names: \n",
    "    feature_names = ['f{0:0>2d}'.format(i) for i in range(shap_values.shape[1] - 1)]\n",
    "model.feature_names = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference dataset used for SHAP computation ## \n",
    "\n",
    "# s3.download_file('BUCKET_NAME', 'DATA_LOCATION', 'shap_reference_data.csv')\n",
    "\n",
    "# This dataset is assumed to *NOT* contain the output label \n",
    "# and have the same number of features as the shap_values\n",
    "data = np.loadtxt('shap_reference_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree plot\n",
    "\n",
    "An XGBoost model consists of an ensemble of classification and regression trees (CART).  Change the `NUM_TREE` value (ordinal number of the target tree) to plot other trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "NUM_TREE = 3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "xgb.plot_tree(model, num_trees=NUM_TREE, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Feature importances\n",
    "\n",
    "XGBoost provides multiple feature importance metrics to understand the influence of each feature on the model.\n",
    "\n",
    "- *gain*: contribution of feature to the model calculated by taking the increase in prediction accuracy ('total_gain' is the sum of all gain across all splits, 'gain' is the average of all gain across all splits)\n",
    "\n",
    "- *cover*: coverage of a feature calculated by the number of data points affected by a split involving the feature ('total_cover' is the sum of all coverage, 'cover' is the average across all splits)\n",
    "\n",
    "- *weight*: percentage representing the relative number of times a particular feature occurs in the trees of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10\n",
    "\n",
    "fig = plt.figure(figsize=(18, 15))\n",
    "fig.suptitle('Feature importances for the top {} features'.format(MAX_FEATURES), fontsize=24)\n",
    "\n",
    "for index, type in enumerate(('gain', 'total_gain', 'cover', 'total_cover', 'weight'), start=1): \n",
    "    ax = fig.add_subplot(3, 2, index)\n",
    "    xgb.plot_importance(model, importance_type=type, title=type,\n",
    "                        ax=ax, grid=False, height=0.4, \n",
    "                        max_num_features=MAX_FEATURES, show_values=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the model using SHAP\n",
    "\n",
    "We use SHAP values as means to understand the contributions of the features to the model predictions. SHAP (SHapley Additive exPlanations) by Lundberg and Lee (2016) is a method to\n",
    "explain individual predictions and is based on the game theoretically optimal\n",
    "Shapley Values.\n",
    "\n",
    "A prediction can be explained by assuming that each feature value of the\n",
    "instance is a “player” in a game where the prediction is the payout. Shapley\n",
    "values – a method from coalitional game theory – tells us how to fairly\n",
    "distribute the “payout” among the features.\n",
    "\n",
    "Reference: \"Explainable machine-learning predictions for the prevention of hypoxaemia during surgery\", Nature Biomedical Engineering, 2018\n",
    "\n",
    "------\n",
    "\n",
    "**Be careful to interpret the Shapley value correctly**: The Shapley value is the\n",
    "average contribution of a feature value to the prediction in different\n",
    "coalitions. The Shapley value is NOT the difference in prediction when we would\n",
    "remove the feature from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP summary\n",
    "\n",
    "A global aggregation of the individual Shapley values gives the overall average contributions of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:-1], feature_names=feature_names, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **summary plot** below can provide more context over the bar chart of feature importances. It tells which features are most important, and also their range of effects over the dataset. The color allows us to match how changes in the value of a feature effect the change in risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:-1], features=data, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP dependence plots\n",
    "\n",
    "A **SHAP dependence plot** shows how the model output varies by feature value while showing the interaction between two features. The feature used for coloring is automatically chosen to highlight what might be driving these interactions. This shows how the model depends on the given feature, and can be considered a richer extenstion of the classical parital dependence plots. Vertical dispersion of the data points represents interaction effects. Grey ticks along the y-axis are data points where the feature’s value was NaN.\n",
    "\n",
    "Here we plot the top ranked features  (ordered by mean absolute SHAP value over all the samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RANKS = 3\n",
    "for r in range(N_RANKS):\n",
    "    shap.dependence_plot(\"rank({})\".format(r), \n",
    "                         shap_values, \n",
    "                         data, \n",
    "                         feature_names=feature_names,\n",
    "                         interaction_index='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP force plots\n",
    "\n",
    "A **force plot** explanation shows how features are contributing to push the model output from the base value (the average model output over the dataset) to the actual prediction. Features pushing the prediction higher are shown in **red**, those pushing the prediction lower are in **blue**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N_ROWS = shap_values.shape[1]\n",
    "N_SAMPLES = min(1000, N_ROWS)\n",
    "sampled_indices = np.random.randint(N_ROWS, size=N_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(baseline_value, \n",
    "                shap_values[sampled_indices, :], \n",
    "                data[sampled_indices, :], \n",
    "                feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Outliers are extreme values that deviate from other observations on data. It's useful to understand the influence of various features for outlier predictions to determine if it's a novelty, an experimental error, or a shortcoming in the model. \n",
    "\n",
    "Here we show force plot for prediction outliers that are on either side of the baseline value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top outliers\n",
    "from scipy import stats\n",
    "N_OUTLIERS = 3  # number of outliers on each side of the tail\n",
    "\n",
    "shap_sum = np.sum(shap_values, axis=1)\n",
    "z_scores = stats.zscore(shap_sum)\n",
    "outlier_indices = (np.argpartition(z_scores, -N_OUTLIERS)[-N_OUTLIERS:]).tolist()\n",
    "outlier_indices += (np.argpartition(z_scores, N_OUTLIERS)[:N_OUTLIERS]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig_index, outlier_index in enumerate(outlier_indices, start=1): \n",
    "    shap.force_plot(baseline_value, \n",
    "                    shap_values[outlier_index, :], \n",
    "                    data[outlier_index, :], \n",
    "                    matplotlib=True, \n",
    "                    feature_names=feature_names) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
